{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtkhufiocSxQCxTalX0RSp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MikkoDT/MexEE402_AI/blob/main/Ch1_2_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chapter 1: Introduction to Data Pre-processing**\n",
        "\n",
        "**Data Preprocessing**\n",
        "\n",
        "- Acts like a backstage crew ensuring smooth data analysis or ML projects.\n",
        "\n",
        "- Comparable to cleaning and organizing a messy kitchen before cooking.\n",
        "\n",
        "- Raw data is often messy, incomplete, inconsistent, or irrelevant.\n",
        "\n",
        "**Common Issues**\n",
        "\n",
        "- Missing Data → some values not recorded\n",
        "\n",
        "- Inconsistent Data → different units/formats\n",
        "\n",
        "- Irrelevant Data → unnecessary features\n",
        "\n",
        "\n",
        "**Preprocessing Techniques**\n",
        "\n",
        "- Handling Missing Data → e.g., imputation (fill with average)\n",
        "\n",
        "- Data Transformation → convert units (e.g., mph → kph)\n",
        "\n",
        "- Feature Selection → remove irrelevant data\n",
        "\n",
        "\n",
        "**Why It’s Essential**\n",
        "\n",
        "1. Improves data quality → fixes inconsistencies, fills gaps\n",
        "\n",
        "2. Enhances model performance → clean data = better accuracy\n",
        "\n",
        "3. Simplifies analysis → easier to find patterns & trends\n",
        "\n",
        "4. Saves resources → prevents issues later, reduces cost & time\n"
      ],
      "metadata": {
        "id": "0XpkrsEz8gCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chapter 2: The Power of Data: Initial Steps in Loading, Understanding, and Exploring Data with Python**\n",
        "\n",
        "**Data Formats**\n",
        "\n",
        "- Common types: CSV, JSON, Excel\n",
        "\n",
        "- Each has unique characteristics\n",
        "\n",
        "- Handling multiple formats is a core data science skill\n",
        "\n",
        "**First Step: Loading Data**\n",
        "\n",
        "- Essential part of data preprocessing\n",
        "\n",
        "- Use Pandas for flexible, powerful data manipulation"
      ],
      "metadata": {
        "id": "R2-n79fV82uk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Download the CSV file\n",
        "\n",
        "For our practical example, download the CSV file for Video Game Sales.\n",
        "https://www.kaggle.com/datasets/gregorut/videogamesales"
      ],
      "metadata": {
        "id": "AfhmiGu587a1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Import Necessary Libraries\n",
        "\n",
        "Before you delve into data processing, you must first import the necessary libraries. In our case, we'll utilize pandas."
      ],
      "metadata": {
        "id": "pI43Tv_y8-VE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cBInBcLG8cZH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Loading Data\n",
        "\n",
        "With your libraries ready, it's time to load your data. Presuming that you have downloaded the CSV file and uploaded it into your Google Colab environment, here's how you read a CSV file using pandas:"
      ],
      "metadata": {
        "id": "gwE39c-Z9On9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/vgsales.csv')"
      ],
      "metadata": {
        "id": "t2Fums4x9NSL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Understanding Data Types\n",
        "\n",
        "Once you've loaded your data, it's beneficial to examine what kind of data you're dealing with.\n",
        "\n",
        "# Understanding Data Types\n",
        "\n",
        "\n",
        "*   Defines the kind of information in each dataset column\n",
        "*   Common types:\n",
        "    - Numeric → integers & floats, support math operations\n",
        "    - Categorical → groups or labels\n",
        "        * Nominal (no order: Red, Green, Blue)\n",
        "        * Ordinal (ordered: Low, Medium, High)\n",
        "    - Datetime → dates & times, crucial for time-series and timestamps\n",
        "\n",
        "* Knowing data types guides preprocessing decisions\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TtihKQ0u9718"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This will print out the data type of each column. For instance, if a column is of 'object' type, it is likely a string or categorical data. If it's 'int64' or 'float64', it's a numerical data.\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NbPxzfd_HUd",
        "outputId": "fa1e3420-5e4a-452d-f71e-0ef953c988b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank              int64\n",
            "Name             object\n",
            "Platform         object\n",
            "Year            float64\n",
            "Genre            object\n",
            "Publisher        object\n",
            "NA_Sales        float64\n",
            "EU_Sales        float64\n",
            "JP_Sales        float64\n",
            "Other_Sales     float64\n",
            "Global_Sales    float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Basic Data Exploration"
      ],
      "metadata": {
        "id": "mMIK7vzO_WR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To get the first five rows of the dataset\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A9xycPs9uOi",
        "outputId": "b06fe12d-18b5-4a71-d46f-52ef5b393fd2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Rank                      Name Platform    Year         Genre Publisher  \\\n",
            "0     1                Wii Sports      Wii  2006.0        Sports  Nintendo   \n",
            "1     2         Super Mario Bros.      NES  1985.0      Platform  Nintendo   \n",
            "2     3            Mario Kart Wii      Wii  2008.0        Racing  Nintendo   \n",
            "3     4         Wii Sports Resort      Wii  2009.0        Sports  Nintendo   \n",
            "4     5  Pokemon Red/Pokemon Blue       GB  1996.0  Role-Playing  Nintendo   \n",
            "\n",
            "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  \n",
            "0     41.49     29.02      3.77         8.46         82.74  \n",
            "1     29.08      3.58      6.81         0.77         40.24  \n",
            "2     15.85     12.88      3.79         3.31         35.82  \n",
            "3     15.75     11.01      3.28         2.96         33.00  \n",
            "4     11.27      8.89     10.22         1.00         31.37  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To get a statistical summary of the dataset\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5X2mtLF-Eou",
        "outputId": "5bf4dbd7-cbe9-484d-d017-52e4516f16e3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Rank          Year      NA_Sales      EU_Sales      JP_Sales  \\\n",
            "count  16598.000000  16327.000000  16598.000000  16598.000000  16598.000000   \n",
            "mean    8300.605254   2006.406443      0.264667      0.146652      0.077782   \n",
            "std     4791.853933      5.828981      0.816683      0.505351      0.309291   \n",
            "min        1.000000   1980.000000      0.000000      0.000000      0.000000   \n",
            "25%     4151.250000   2003.000000      0.000000      0.000000      0.000000   \n",
            "50%     8300.500000   2007.000000      0.080000      0.020000      0.000000   \n",
            "75%    12449.750000   2010.000000      0.240000      0.110000      0.040000   \n",
            "max    16600.000000   2020.000000     41.490000     29.020000     10.220000   \n",
            "\n",
            "        Other_Sales  Global_Sales  \n",
            "count  16598.000000  16598.000000  \n",
            "mean       0.048063      0.537441  \n",
            "std        0.188588      1.555028  \n",
            "min        0.000000      0.010000  \n",
            "25%        0.000000      0.060000  \n",
            "50%        0.010000      0.170000  \n",
            "75%        0.040000      0.470000  \n",
            "max       10.570000     82.740000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To get a brief overview of the dataset\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVkbaR-h-_RL",
        "outputId": "d3a211e5-44c1-48b4-e46c-aa125106fe1f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16598 entries, 0 to 16597\n",
            "Data columns (total 11 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Rank          16598 non-null  int64  \n",
            " 1   Name          16598 non-null  object \n",
            " 2   Platform      16598 non-null  object \n",
            " 3   Year          16327 non-null  float64\n",
            " 4   Genre         16598 non-null  object \n",
            " 5   Publisher     16540 non-null  object \n",
            " 6   NA_Sales      16598 non-null  float64\n",
            " 7   EU_Sales      16598 non-null  float64\n",
            " 8   JP_Sales      16598 non-null  float64\n",
            " 9   Other_Sales   16598 non-null  float64\n",
            " 10  Global_Sales  16598 non-null  float64\n",
            "dtypes: float64(6), int64(1), object(4)\n",
            "memory usage: 1.4+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chapter 3: Cleaning Your Data**\n",
        "## Data Cleaning\n",
        "\n",
        "* Messy data hinders insights → clean data = reliable analysis\n",
        "\n",
        "* Key step in data preprocessing\n",
        "\n",
        "Handling Missing Values\n",
        "\n",
        "* Common issue in datasets\n",
        "\n",
        "* Strategies:\n",
        "\n",
        "    - Imputation → fill with mean/median/etc.\n",
        "\n",
        "    - Deletion → remove rows/columns\n",
        "\n",
        "    - Prediction → estimate using models"
      ],
      "metadata": {
        "id": "dtId5Mh_AHO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Import Necessary Libraries\n",
        "\n",
        "In this case, we require numpy."
      ],
      "metadata": {
        "id": "-1T-Bi2VBSxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "9f_NS6lB_Bhn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Locate Missing Values\n",
        "\n",
        "Our next step is to identify where the missing values reside in our dataset."
      ],
      "metadata": {
        "id": "Bw6j81-4BfxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This command displays the number of missing values in each column.\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbZSScelBe52",
        "outputId": "cc07a1c0-09ac-497a-bccb-419c0c430909"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank              0\n",
            "Name              0\n",
            "Platform          0\n",
            "Year            271\n",
            "Genre             0\n",
            "Publisher        58\n",
            "NA_Sales          0\n",
            "EU_Sales          0\n",
            "JP_Sales          0\n",
            "Other_Sales       0\n",
            "Global_Sales      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 3: Handle Missing Values"
      ],
      "metadata": {
        "id": "QljYywabBycb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imputation**\n",
        "\n",
        "* Replace missing data with computed values\n",
        "\n",
        "* For numeric columns → use mean / median / mode\n",
        "\n",
        "* For categorical columns → use most frequent (mode)\n",
        "\n",
        "* Example:\n",
        "\n",
        "    - Year (numeric) → mean imputation\n",
        "\n",
        "    - Publisher (categorical) → mode imputation"
      ],
      "metadata": {
        "id": "EmnGMSiiCDwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Year'].fillna(df['Year'].mean(), inplace=True)\n",
        "df['Publisher'].fillna(df['Publisher'].mode()[0], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieNQsU4EBoSa",
        "outputId": "7475ec07-bf59-49ce-d07e-16ea87f32e4e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-724162019.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Year'].fillna(df['Year'].mean(), inplace=True)\n",
            "/tmp/ipython-input-724162019.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Publisher'].fillna(df['Publisher'].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deletion**\n",
        "\n",
        "* Remove rows/columns with missing values\n",
        "\n",
        "* Useful if only a small portion of data is missing\n",
        "\n",
        "* Done with notna() in Pandas\n",
        "\n",
        "⚠️ Risk: may lose important information"
      ],
      "metadata": {
        "id": "BzlB0hYFDKhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keep rows where 'Publisher' is not missing\n",
        "df = df[df['Publisher'].notna()]"
      ],
      "metadata": {
        "id": "SuVJ9kvWCPxN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction**\n",
        "\n",
        "* Use ML models to predict and fill missing values\n",
        "\n",
        "* Based on patterns in other available data\n",
        "\n",
        "* More complex and computationally demanding\n",
        "\n",
        "* Useful when:\n",
        "\n",
        "    - Large amount of missing data\n",
        "\n",
        "    - Simpler methods (imputation/deletion) aren’t effective"
      ],
      "metadata": {
        "id": "-aNjP4FKEJ4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Confirm Your Results\n",
        "\n",
        "Finally, we'll confirm our work by checking for missing values again:"
      ],
      "metadata": {
        "id": "wuoWtv-BEXmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xog6MrztDd2R",
        "outputId": "4ff91527-9588-4347-a516-65064f8c6ee1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank            0\n",
            "Name            0\n",
            "Platform        0\n",
            "Year            0\n",
            "Genre           0\n",
            "Publisher       0\n",
            "NA_Sales        0\n",
            "EU_Sales        0\n",
            "JP_Sales        0\n",
            "Other_Sales     0\n",
            "Global_Sales    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### You should now see that the count of missing values in the 'Year' and 'Publisher' columns is zero. Now, you've successfully handled missing data in your dataset."
      ],
      "metadata": {
        "id": "wSvm7OgFEhxs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Removing Redundancies**\n",
        "\n",
        "* Eliminate unnecessary data to improve quality\n",
        "\n",
        "* Common redundancies:\n",
        "\n",
        "  - Duplicate entries\n",
        "\n",
        "  - Irrelevant features\n",
        "\n",
        "  - Noisy data"
      ],
      "metadata": {
        "id": "BdEyuCeyExJj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Eliminate Redundancies\n",
        "\n",
        "**Duplicate Entries**\n",
        "\n",
        "* Rows that appear more than once\n",
        "\n",
        "* Can skew results if not removed\n",
        "\n",
        "* Pandas tools:\n",
        "\n",
        "    - duplicated() → find duplicates\n",
        "\n",
        "    - drop_duplicates() → remove duplicates"
      ],
      "metadata": {
        "id": "4e-LaCGhFYex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.duplicated().sum())\n",
        "\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "print(df.duplicated().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8VbCdc5EbL7",
        "outputId": "df4d9a3b-701d-4fec-ada6-b991f7af2fca"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Irrelevant Features**\n",
        "\n",
        "* Variables that don’t contribute to analysis or prediction\n",
        "\n",
        "* Should be removed to avoid noise\n",
        "\n",
        "* Pandas tool: drop()\n",
        "\n",
        "* Example: drop Rank column if not useful"
      ],
      "metadata": {
        "id": "pHAN3FlxF10B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['Rank'], axis=1)"
      ],
      "metadata": {
        "id": "loG9YZtfFuSX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Noisy Data**\n",
        "\n",
        "* Data that is inconsistent or has extreme outliers\n",
        "\n",
        "* Can distort patterns and lead to inaccurate results\n",
        "\n",
        "* Sources:\n",
        "\n",
        "    - Inconsistent entries\n",
        "\n",
        "    - Human errors\n",
        "\n",
        "    - Unrealistic values (e.g., extreme sales numbers)\n",
        "\n",
        "* Example: treat games with Global Sales > 40M as outliers and remove them"
      ],
      "metadata": {
        "id": "yzwGc1laGGCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This line keeps only the rows where 'Global_Sales' is less than or equal to 40.\n",
        "df = df[df['Global_Sales'] <= 40]"
      ],
      "metadata": {
        "id": "BXZjdxA1F-2W"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Validate Your Results\n",
        "Lastly, let's examine our cleaned DataFrame:"
      ],
      "metadata": {
        "id": "KGAKgvytGX2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHF2OXY5GSQA",
        "outputId": "4ae5c95b-aefb-45e2-80cc-4b10e3ca0e25"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       Name Platform    Year         Genre Publisher  \\\n",
            "2            Mario Kart Wii      Wii  2008.0        Racing  Nintendo   \n",
            "3         Wii Sports Resort      Wii  2009.0        Sports  Nintendo   \n",
            "4  Pokemon Red/Pokemon Blue       GB  1996.0  Role-Playing  Nintendo   \n",
            "5                    Tetris       GB  1989.0        Puzzle  Nintendo   \n",
            "6     New Super Mario Bros.       DS  2006.0      Platform  Nintendo   \n",
            "\n",
            "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  \n",
            "2     15.85     12.88      3.79         3.31         35.82  \n",
            "3     15.75     11.01      3.28         2.96         33.00  \n",
            "4     11.27      8.89     10.22         1.00         31.37  \n",
            "5     23.20      2.26      4.22         0.58         30.26  \n",
            "6     11.38      9.23      6.50         2.90         30.01  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ratjG-vbGcn_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}